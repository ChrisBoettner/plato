{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from astropy.table import Table\n",
    "from astropy.units import UnitsWarning\n",
    "from tqdm import tqdm\n",
    "\n",
    "from plato.stars import classify_stars, quality_cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 392000/2675538 stars based on quality cuts (17.2%).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving Kinematic Parameter: 100%|██████████| 2283538/2283538 [14:15<00:00, 2668.65it/s]\n"
     ]
    }
   ],
   "source": [
    "# process targets\n",
    "targets = Table.read(\"../data/raw/plato_targets.fits\").to_pandas()\n",
    "\n",
    "# make quality cuts\n",
    "targets = quality_cuts(targets, max_error=0.2)\n",
    "\n",
    "# add classification\n",
    "targets = classify_stars(targets, include_galactic_quantities=True)\n",
    "\n",
    "# rename columns\n",
    "targets.rename(\n",
    "    columns={\n",
    "        \"SOURCE_ID\": \"gaiaID_DR3\",\n",
    "        \"dr2_source_id\": \"gaiaID_DR2\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "for col in targets.columns:\n",
    "    if col.endswith(\"_error\"):\n",
    "        targets.rename(columns={col: f\"e_{col[:-6]}\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks: 100%|██████████| 18/18 [02:21<00:00,  7.84s/it]\n"
     ]
    }
   ],
   "source": [
    "# add xgboost metallicities from Andrae2023\n",
    "total_rows = 174922161\n",
    "chunksize = int(1e7)\n",
    "xgboost_data = []\n",
    "\n",
    "# load in chuncks\n",
    "for chunk in tqdm(\n",
    "    pd.read_csv(\n",
    "        \"../data/external/xgboost.csv\",\n",
    "        chunksize=chunksize,\n",
    "        compression=\"gzip\",\n",
    "        usecols=[\"source_id\", \"mh_xgboost\"],\n",
    "    ),\n",
    "    total=total_rows // chunksize + 1,\n",
    "    desc=\"Processing chunks: \",\n",
    "):\n",
    "    # Select only the targets\n",
    "    filtered_chunk = chunk[chunk[\"source_id\"].isin(targets[\"gaiaID_DR3\"])]\n",
    "    xgboost_data.append(filtered_chunk)\n",
    "\n",
    "xgboost_data = pd.concat(xgboost_data).rename(columns={\"source_id\": \"gaiaID_DR3\"})\n",
    "xgboost_data = xgboost_data.assign(mh_xgboost_lower=np.nan, mh_xgboost_upper=np.nan)\n",
    "targets = targets.merge(xgboost_data, on=\"gaiaID_DR3\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add metallicity and alpha from medium-res spectroscopy, photometry, or xgboost\n",
    "\n",
    "targets[\"[Fe/H]\"] = np.nan\n",
    "targets[\"e_[Fe/H]_lower\"] = np.nan\n",
    "targets[\"e_[Fe/H]_upper\"] = np.nan\n",
    "targets[\"[Fe/H]_source\"] = \"\"\n",
    "# add [Fe/H] metallcity in following priority: gspspec, gspphot, xgboost (use next possible source if previous is NaN)\n",
    "sources = [\"mh_gspspec\", \"mh_gspphot\", \"mh_xgboost\"]\n",
    "for source in sources:\n",
    "    mask = targets[f\"{source}\"].notnull() & targets[\"[Fe/H]\"].isnull()\n",
    "    targets.loc[mask, \"[Fe/H]\"] = targets[f\"{source}\"]\n",
    "    targets.loc[mask, \"e_[Fe/H]_lower\"] = targets[f\"{source}_lower\"]\n",
    "    targets.loc[mask, \"e_[Fe/H]_upper\"] = targets[f\"{source}_upper\"]\n",
    "    targets.loc[mask, \"[Fe/H]_source\"] = f\"{source}\"\n",
    "\n",
    "# rename alphafe_gspspec column (and errors) to [alpha/Fe]\n",
    "targets.rename(\n",
    "    columns={\n",
    "        \"alphafe_gspspec\": \"[alpha/Fe]\",\n",
    "        \"alphafe_gspspec_lower\": \"e_[alpha/Fe]_lower\",\n",
    "        \"alphafe_gspspec_upper\": \"e_[alpha/Fe]_upper\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "# drop original metallicity columns and their errors\n",
    "targets.drop(\n",
    "    columns=[\n",
    "        f\"{source}{suffix}\" for source in sources for suffix in [\"\", \"_lower\", \"_upper\"]\n",
    "    ],\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add metallicities and alpha from high-res spectroscopic surveys\n",
    "\n",
    "## Apogee\n",
    "apogee = Table.read(\"../data/external/apogee.fits\", hdu=1)\n",
    "# get relevant columns\n",
    "apogee = apogee[\n",
    "    [\"GAIAEDR3_SOURCE_ID\", \"FE_H\", \"FE_H_ERR\", \"ALPHA_M\", \"ALPHA_M_ERR\", \"ASPCAPFLAGS\"]\n",
    "]\n",
    "apogee_df = apogee.to_pandas()\n",
    "# qulaity cuts (drop entries where ALPHA_M or M_H is flagged)\n",
    "apogee_df = apogee_df[\n",
    "    ~apogee_df[\"ASPCAPFLAGS\"].astype(str).str.contains(\"ALPHA_M|M_H|SN_WARN\")\n",
    "]\n",
    "\n",
    "apogee_df = apogee_df.rename(\n",
    "    columns={\n",
    "        \"GAIAEDR3_SOURCE_ID\": \"gaiaID_DR3\",\n",
    "        \"FE_H\": \"[Fe/H]_apogee\",\n",
    "        \"FE_H_ERR\": \"e_[Fe/H]_apogee\",\n",
    "        \"ALPHA_M\": \"[alpha/M]_apogee\",\n",
    "        \"ALPHA_M_ERR\": \"e_[alpha/M]_apogee\",\n",
    "    }\n",
    ")\n",
    "# merge into targets\n",
    "targets = pd.merge(\n",
    "    targets,\n",
    "    apogee_df.drop_duplicates(subset=\"gaiaID_DR3\", keep=\"first\"),\n",
    "    on=\"gaiaID_DR3\",\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "## GALAH\n",
    "with warnings.catch_warnings():\n",
    "    # silence warning for log(cm.s**-2) units\n",
    "    warnings.simplefilter(\"ignore\", UnitsWarning)\n",
    "    galah = Table.read(\"../data/external/galah.fits\")\n",
    "# quality cuts\n",
    "galah = galah[galah[\"flag_sp\"] == 0]\n",
    "galah = galah[galah[\"flag_fe_h\"] == 0]\n",
    "galah = galah[galah[\"flag_alpha_fe\"] == 0]\n",
    "# get relevant columns\n",
    "galah = galah[[\"dr3_source_id\", \"fe_h\", \"e_fe_h\", \"alpha_fe\", \"e_alpha_fe\"]]\n",
    "galah_df = galah.to_pandas()\n",
    "galah_df = galah_df.rename(\n",
    "    columns={\n",
    "        \"dr3_source_id\": \"gaiaID_DR3\",\n",
    "        \"fe_h\": \"[Fe/H]_galah\",\n",
    "        \"e_fe_h\": \"e_[Fe/H]_galah\",\n",
    "        \"alpha_fe\": \"[alpha/Fe]_galah\",\n",
    "        \"e_alpha_fe\": \"e_[alpha/Fe]_galah\",\n",
    "    }\n",
    ")\n",
    "# merge into targets\n",
    "targets = pd.merge(\n",
    "    targets,\n",
    "    galah_df.drop_duplicates(subset=\"gaiaID_DR3\", keep=\"first\"),\n",
    "    on=\"gaiaID_DR3\",\n",
    "    how=\"left\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# process asPIC\n",
    "\n",
    "asPIC = Table.read(f\"../data/external/asPIC_1.1.fits\")\n",
    "asPIC = asPIC[\n",
    "    [\n",
    "        \"sourceId\",\n",
    "        \"GLON\",\n",
    "        \"GLAT\",\n",
    "        \"gaiaV\",\n",
    "        \"egaiaV\",\n",
    "        \"Gmag\",\n",
    "        \"eGmag\",\n",
    "        \"Radius\",\n",
    "        \"eRadius\",\n",
    "        \"Mass\",\n",
    "        \"eMass\",\n",
    "        \"Teff\",\n",
    "        \"eTeff\",\n",
    "        \"sourceFlag\",\n",
    "    ]\n",
    "]\n",
    "for col in asPIC.colnames:\n",
    "    asPIC[col] = asPIC[col][:, 0]\n",
    "asPIC = asPIC.to_pandas()\n",
    "\n",
    "# rename source flag\n",
    "asPIC.rename(\n",
    "    columns={\n",
    "        \"sourceId\": \"gaiaID_DR2\",\n",
    "        \"sourceFlag\": \"Stellar Type\",\n",
    "        \"egaiaV\": \"e_gaiaV\",\n",
    "        \"eGmag\": \"e_Gmag\",\n",
    "        \"eRadius\": \"e_Radius\",\n",
    "        \"eMass\": \"e_Mass\",\n",
    "        \"eTeff\": \"e_Teff\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "asPIC[\"Stellar Type\"] = asPIC[\"Stellar Type\"].map(\n",
    "    {\n",
    "        1: \"FGK\",  # FGK\n",
    "        5: \"FGK\",  # FGK and known planet host\n",
    "        2: \"M\",  # M\n",
    "        6: \"M\",  # M and known planet host\n",
    "    }\n",
    ")\n",
    "\n",
    "# match asPIC and targets on sourceId\n",
    "data = pd.merge(targets, asPIC, on=\"gaiaID_DR2\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "data.to_csv(\"../data/processed/all_sky_targets.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plato",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
